{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LVQ for the Ionosphere Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ionosphere Case Study\n",
        "In this section, we will apply the Learning Vector Quantization algorithm to the Ionosphere\n",
        "dataset. The first step is to load the dataset and convert the loaded data to numbers that\n",
        "we can use with the Euclidean distance calculation. For this we will use the helper function\n",
        "load csv() to load the file, str column to float() to convert string numbers to floats and\n",
        "str column to int() to convert the class column to integer values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will evaluate the algorithm using k-fold cross-validation with 5 folds. This means\n",
        "that 351/5 = 70.2 or just over 70 records will be in each fold. We will use the helper functions\n",
        "evaluate algorithm() to evaluate the algorithm with cross-validation and accuracy metric()\n",
        "to calculate the accuracy of predictions. The complete example is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor _ in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        "\n",
        "# calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "\tdistance = 0.0\n",
        "\tfor i in range(len(row1)-1):\n",
        "\t\tdistance += (row1[i] - row2[i])**2\n",
        "\treturn sqrt(distance)\n",
        "\n",
        "# Locate the best matching unit\n",
        "def get_best_matching_unit(codebooks, test_row):\n",
        "\tdistances = list()\n",
        "\tfor codebook in codebooks:\n",
        "\t\tdist = euclidean_distance(codebook, test_row)\n",
        "\t\tdistances.append((codebook, dist))\n",
        "\tdistances.sort(key=lambda tup: tup[1])\n",
        "\treturn distances[0][0]\n",
        "\n",
        "# Make a prediction with codebook vectors\n",
        "def predict(codebooks, test_row):\n",
        "\tbmu = get_best_matching_unit(codebooks, test_row)\n",
        "\treturn bmu[-1]\n",
        "\n",
        "# Create a random codebook vector\n",
        "def random_codebook(train):\n",
        "\tn_records = len(train)\n",
        "\tn_features = len(train[0])\n",
        "\tcodebook = [train[randrange(n_records)][i] for i in range(n_features)]\n",
        "\treturn codebook\n",
        "\n",
        "# Train a set of codebook vectors\n",
        "def train_codebooks(train, n_codebooks, lrate, epochs):\n",
        "\tcodebooks = [random_codebook(train) for i in range(n_codebooks)]\n",
        "\tfor epoch in range(epochs):\n",
        "\t\trate = lrate * (1.0-(epoch/float(epochs)))\n",
        "\t\tfor row in train:\n",
        "\t\t\tbmu = get_best_matching_unit(codebooks, row)\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\terror = row[i] - bmu[i]\n",
        "\t\t\t\tif bmu[-1] == row[-1]:\n",
        "\t\t\t\t\tbmu[i] += rate * error\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tbmu[i] -= rate * error\n",
        "\treturn codebooks\n",
        "\n",
        "# LVQ Algorithm\n",
        "def learning_vector_quantization(train, test, n_codebooks, lrate, epochs):\n",
        "\tcodebooks = train_codebooks(train, n_codebooks, lrate, epochs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict(codebooks, row)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running this example prints the classification accuracy on each fold and the mean classification accuracy across all folds. We can see that the \n",
        "accuracy is better than the baseline of 64%. We can also see that our library of 20 codebook vectors is far fewer than\n",
        "holding the entire training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test LVQ on Ionosphere dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'ionosphere.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "learn_rate = 0.3\n",
        "n_epochs = 50\n",
        "n_codebooks = 20\n",
        "scores = evaluate_algorithm(dataset, learning_vector_quantization, n_folds, n_codebooks, learn_rate, n_epochs)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}