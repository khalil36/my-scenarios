{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## Cross-Validation Algorithm Test Harness\n", 
        "Cross-validation is a resampling technique that provides more reliable estimates of algorithm\n", 
        "performance on unseen data. It requires the creation and evaluation of k models on different\n", 
        "subsets of your data, and as such is more computationally expensive. Nevertheless, it is the\n", 
        "gold standard for evaluating machine learning algorithms"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# Example of a Cross Validation Test Harness\n", 
        "from random import seed\n", 
        "from random import randrange\n", 
        "from csv import reader"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "# Load a CSV file\n", 
        "def load_csv(filename):\n", 
        "\tdataset = list()\n", 
        "\twith open(filename, 'r') as file:\n", 
        "\t\tcsv_reader = reader(file)\n", 
        "\t\tfor row in csv_reader:\n", 
        "\t\t\tif not row:\n", 
        "\t\t\t\tcontinue\n", 
        "\t\t\tdataset.append(row)\n", 
        "\treturn dataset\n", 
        "\n", 
        "# Convert string column to float\n", 
        "def str_column_to_float(dataset, column):\n", 
        "\tfor row in dataset:\n", 
        "\t\trow[column] = float(row[column].strip())\n", 
        "\n", 
        "# Split a dataset into k folds\n", 
        "def cross_validation_split(dataset, n_folds):\n", 
        "\tdataset_split = list()\n", 
        "\tdataset_copy = list(dataset)\n", 
        "\tfold_size = int(len(dataset) / n_folds)\n", 
        "\tfor _ in range(n_folds):\n", 
        "\t\tfold = list()\n", 
        "\t\twhile len(fold) < fold_size:\n", 
        "\t\t\tindex = randrange(len(dataset_copy))\n", 
        "\t\t\tfold.append(dataset_copy.pop(index))\n", 
        "\t\tdataset_split.append(fold)\n", 
        "\treturn dataset_split\n", 
        "\n", 
        "# Calculate accuracy percentage\n", 
        "def accuracy_metric(actual, predicted):\n", 
        "\tcorrect = 0\n", 
        "\tfor i in range(len(actual)):\n", 
        "\t\tif actual[i] == predicted[i]:\n", 
        "\t\t\tcorrect += 1\n", 
        "\treturn correct / float(len(actual)) * 100.0\n", 
        "\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Although slightly more complex in code and slower to run, this function provides a more\n", 
        "robust estimate of algorithm performance. We can tie all of this together with a complete\n", 
        "example on the diabetes dataset with the Zero Rule algorithm."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# Evaluate an algorithm using a cross validation split\n", 
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n", 
        "\tfolds = cross_validation_split(dataset, n_folds)\n", 
        "\tscores = list()\n", 
        "\tfor fold in folds:\n", 
        "\t\ttrain_set = list(folds)\n", 
        "\t\ttrain_set.remove(fold)\n", 
        "\t\ttrain_set = sum(train_set, [])\n", 
        "\t\ttest_set = list()\n", 
        "\t\tfor row in fold:\n", 
        "\t\t\trow_copy = list(row)\n", 
        "\t\t\ttest_set.append(row_copy)\n", 
        "\t\t\trow_copy[-1] = None\n", 
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n", 
        "\t\tactual = [row[-1] for row in fold]\n", 
        "\t\taccuracy = accuracy_metric(actual, predicted)\n", 
        "\t\tscores.append(accuracy)\n", 
        "\treturn scores\n", 
        "\n", 
        "# zero rule algorithm for classification\n", 
        "def zero_rule_algorithm_classification(train, test):\n", 
        "\toutput_values = [row[-1] for row in train]\n", 
        "\tprediction = max(set(output_values), key=output_values.count)\n", 
        "\tpredicted = [prediction for i in range(len(test))]\n", 
        "\treturn predicted\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "A total of 5 cross-validation folds are used to evaluate the Zero Rule Algorithm. As such,\n", 
        "5 scores are returned from the evaluate algorithm() algorithm. Running this example both\n", 
        "prints these list of scores calculated and prints the mean score."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# Test cross validation test harness\n", 
        "seed(1)\n", 
        "# load and prepare data\n", 
        "filename = 'pima-indians-diabetes.csv'\n", 
        "dataset = load_csv(filename)\n", 
        "for i in range(len(dataset[0])):\n", 
        "\tstr_column_to_float(dataset, i)\n", 
        "# evaluate algorithm\n", 
        "n_folds = 5\n", 
        "scores = evaluate_algorithm(dataset, zero_rule_algorithm_classification, n_folds)\n", 
        "print('Scores: %s' % scores)\n", 
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/len(scores)))"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}