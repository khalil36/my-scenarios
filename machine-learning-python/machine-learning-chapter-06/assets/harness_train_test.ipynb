{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# Example of a Train-Test Test Harness\n", 
        "from random import seed\n", 
        "from random import randrange\n", 
        "from csv import reader\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "## Train-Test Algorithm Test Harness\n", 
        "The train-test split is a simple resampling method that can be used to evaluate a machine\n", 
        "learning algorithm. As such, it is a good starting point for developing a test harness. <br />\n", 
        "\n", 
        "Below  function takes a dataset and an algorithm and return a performance score. It takes 3 fixed arguments\n", 
        "including the dataset, the algorithm function and the split percentage for the train-test split.\n", 
        "First, the dataset is split into train and test elements. Next, a copy of the test set is made\n", 
        "and each output value is cleared by setting it to the None value to prevent the algorithm from\n", 
        "cheating accidentally."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# Load a CSV file\n", 
        "def load_csv(filename):\n", 
        "\tdataset = list()\n", 
        "\twith open(filename, 'r') as file:\n", 
        "\t\tcsv_reader = reader(file)\n", 
        "\t\tfor row in csv_reader:\n", 
        "\t\t\tif not row:\n", 
        "\t\t\t\tcontinue\n", 
        "\t\t\tdataset.append(row)\n", 
        "\treturn dataset\n", 
        "\n", 
        "# Convert string column to float\n", 
        "def str_column_to_float(dataset, column):\n", 
        "\tfor row in dataset:\n", 
        "\t\trow[column] = float(row[column].strip())\n", 
        "\n", 
        "# Split a dataset into a train and test set\n", 
        "def train_test_split(dataset, split):\n", 
        "\ttrain = list()\n", 
        "\ttrain_size = split * len(dataset)\n", 
        "\tdataset_copy = list(dataset)\n", 
        "\twhile len(train) < train_size:\n", 
        "\t\tindex = randrange(len(dataset_copy))\n", 
        "\t\ttrain.append(dataset_copy.pop(index))\n", 
        "\treturn train, dataset_copy\n", 
        "\n", 
        "# Calculate accuracy percentage\n", 
        "def accuracy_metric(actual, predicted):\n", 
        "\tcorrect = 0\n", 
        "\tfor i in range(len(actual)):\n", 
        "\t\tif actual[i] == predicted[i]:\n", 
        "\t\t\tcorrect += 1\n", 
        "\treturn correct / float(len(actual)) * 100.0\n", 
        "\n", 
        "# Evaluate an algorithm using a train/test split\n", 
        "def evaluate_algorithm(dataset, algorithm, split, *args):\n", 
        "\ttrain, test = train_test_split(dataset, split)\n", 
        "\ttest_set = list()\n", 
        "\tfor row in test:\n", 
        "\t\trow_copy = list(row)\n", 
        "\t\trow_copy[-1] = None\n", 
        "\t\ttest_set.append(row_copy)\n", 
        "\tpredicted = algorithm(train, test_set, *args)\n", 
        "\tactual = [row[-1] for row in test]\n", 
        "\taccuracy = accuracy_metric(actual, predicted)\n", 
        "\treturn accuracy"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Let\u2019s piece this together with a worked example. We will use the Pima Indians Diabetes\n", 
        "dataset and evaluate the Zero Rule algorithm."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# zero rule algorithm for classification\n", 
        "def zero_rule_algorithm_classification(train, test):\n", 
        "\toutput_values = [row[-1] for row in train]\n", 
        "\tprediction = max(set(output_values), key=output_values.count)\n", 
        "\tpredicted = [prediction for i in range(len(test))]\n", 
        "\treturn predicted\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "The dataset was split into 60% for training the model and 40% for evaluating it. Notice\n", 
        "how the name of the Zero Rule algorithm zero rule algorithm classification was passed\n", 
        "as an argument to the evaluate algorithm() function..Running the following example prints out the\n", 
        "accuracy of the model. <br />\n", 
        "Accuracy: 67.427%"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# Test the train/test harness\n", 
        "seed(1)\n", 
        "# load and prepare data\n", 
        "filename = 'pima-indians-diabetes.csv'\n", 
        "dataset = load_csv(filename)\n", 
        "for i in range(len(dataset[0])):\n", 
        "\tstr_column_to_float(dataset, i)\n", 
        "# evaluate algorithm\n", 
        "split = 0.6\n", 
        "accuracy = evaluate_algorithm(dataset, zero_rule_algorithm_classification, split)\n", 
        "print('Accuracy: %.3f%%' % (accuracy))"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}